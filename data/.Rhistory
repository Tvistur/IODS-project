bins
# create categorical variable crime
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
# look at the table of new variable
table(crime)
# remove original crim from dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)
# add new categorical variable to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
# Chunk 8: divide into train and test sets
# create object n for number of rows in Boston dataset
n <- nrow(boston_scaled)
# choose randomly 80% of rows
ind <- sample(n, size = n*0.8)
# create TRAIN set
train <- boston_scaled[ind,]
# create TEST set
test <-  boston_scaled[-ind,]
# Chunk 9: LDA
# fit LDA to train set
lda.fit <- lda(data = train, crime ~.)
# print lda.fit object
lda.fit
# arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$crime)
# plot results
plot(lda.fit, dimen = 2, col = classes, pch =classes)
lda.arrows(lda.fit, myscale = 1)
# Chunk 10
# save correct classes from test data
correct_classes <- test$crime
# remove the crime variable from test data
test <- dplyr::select(test, -crime)
# Chunk 11: predict LDA
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
# crosstabulate
table(correct = correct_classes, predicted = lda.pred$class)
# Chunk 12: reload data
# reload Boston dataset
data("Boston")
# standardize
boston_scaled2 <- scale(Boston)
# Chunk 13: distances
# Euclidean distance matrix
dist <- dist(boston_scaled2)
summary(dist)
# Chunk 14: k-means
# k-means clustering / Euclidean
km <- kmeans(dist, centers = 10)
# Chunk 15: optimal
# determine number of clusters
k_max <- 5
# calculate WCSS
twcss <- sapply(1:k_max, function(k){kmeans(dist, k)$tot.withinss})
# optimalm number of clusters
qplot(x = 1:k_max, y = twcss, geom = "line") # drops at 2
# run k-means again with optimal number of clusters
km <- kmeans(dist, centers = 2)
# visualize with optimal number of clusters
pairs(boston_scaled2, col = km$cluster)
# Chunk 16: bonus
# k-mean with 5 clusters
km_bonus <- kmeans(dist, centers = 5)
lda.fit_bonus <- lda(data = train, km_bonus ~.)
model_predictors <- dplyr::select(train, -crime)
dim(model_predictors)
dim(lda.fit$scaling)
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
library(Plotly)
install.packages("Plotly")
library(Plotly)
?plot_ly
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = classes)
install.packages("plotly")
library(plotly)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = classes)
install.packages(c("data.table", "lmtest", "mgcv"))
?qplot
dim(model_predictors)
dim(lda.fit$scaling)
pairs(Boston)
pairs(Boston)
pairs(Boston)
getwd()
setwd("~/Documents/IODS K17/IODS-project/data")
hd <- read.csv(http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/"human_development.csv", stringAsFactors = F)
hd <- read.csv(http:/s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/"human_development.csv", stringAsFactors = F)
hd <- read.csv(s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv, stringAsFactors = F)
hd <- read.csv("s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringAsFactors = F)
hd <- read.csv("s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", sep = ";", header = TRUE, stringAsFactors = F)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", sep = ";", header = TRUE, stringAsFactors = F)
hd <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", sep = ";", header = TRUE, stringAsFactors = F)
sep = ";", header = TRUE, stringAsFactors = FALSE)
sep = "\t", header = TRUE, stringAsFactors = FALSE)
sep="\t", header = TRUE, stringAsFactors = FALSE)
header = TRUE, stringAsFactors = FALSE)
stringAsFactors = FALSE)
stringAsFactors=FALSE)
stringsAsFactors=FALSE)
options(stringsAsFactors = FALSE)
hd <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv")
header = TRUE, sep = "\t")
hd <- read.csv(file = "http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv",
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv",
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv",header = TRUE, sep = "\t")
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", sep = "\t", header = TRUE)
hd <- read.csv("http://www.s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", sep = "\t", header = TRUE)
gii <- read.csv("http://www.a3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", na.strings = "..")
gii <- read.csv("http://a3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", na.strings = "..")
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", sep = "\t", header = TRUE)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", na.strings = "..")
str(hd)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", sep = ";", header = TRUE)
str(hd)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", sep = ";", header = TRUE)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", sep = ";", header = TRUE, na.strings = "..")
str(gii)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv")
str(hd)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", na.strings = "..")
str(gii)
dim(hd)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)
View(hd)
View(hd)
View(hd)
View(hd)
colnames(hd)[1] <- "HDI_rank"
colnames(hd)[3] <- "HDI"
colnames(hd)[4] <- "life_exp"
colnames(hd)[5] <- "edu_exp"
colnames(hd)[6] <- "edu_mean"
colnames(hd)[7] <- "GNI"
colnames(hd)[8] <- "GNI_rank"
colnames(hd)
colnames(gii)
colnames(hd)[8] <- "GNI_netrank"
colnames(hd)
colnames(gii)
colnames(gii)[1] <- "GII_rank"
colnames(gii)[3] <- "GII"
colnames(gii)[4] <- "mat_mort"
colnames(gii)[5] <- "adol_birht"
colnames(gii)[6] <- "parl_rep"
colnames(gii)[7] <- "male_labour"
colnames(gii)[8] <- "female_labour"
colnames(gii)
colnames(gii)[1] <- "GII_rank"
colnames(gii)[3] <- "GII"
colnames(gii)[4] <- "mat_mort"
colnames(gii)[5] <- "adol_birht"
colnames(gii)[6] <- "parl_rep"
colnames(gii)[7] <- "labour_male"
colnames(gii)[8] <- "labour_female"
colnames(gii)[2] <- "country"
colnames(gii)
View(hd)
View(hd)
View(gii)
View(gii)
colnames(gii)[7] <- "lab_male"
colnames(gii)[8] <- "lab_female"
colnames(gii)
colnames(gii)[1] <- "GII_rank"
colnames(gii)[2] <- "country"
colnames(gii)[3] <- "GII"
colnames(gii)[4] <- "mat_mort"
colnames(gii)[5] <- "adol_birht"
colnames(gii)[6] <- "parl_rep"
colnames(gii)[7] <- "ed2F"
colnames(gii)[8] <- "ed2M"
colnames(gii)[9] <- "labF"
colnames(gii)[10] <- "labM"
colnames(gii)
View(gii)
View(gii)
colnames(gii)[7] <- "edu2F"
colnames(gii)[8] <- "edu2M"
colnames(gii)
gii <- mutate(gii, edu2F/edu2M = edu2F / edu2M)
gii <- mutate(gii, edu2F/edu2M = (edu2F / edu2M))
gii <- mutate(gii, edu2F/edu2M = edu2F/edu2M)
gii <- mutate(gii, edu2F_edu2M = edu2F/edu2M)
colnames(gii)
gii <- mutate(gii, labF_lab_M = labF / labM)
colnames(gii)
View(gii)
write.csv(learning2014_new, file = "learning2014.csv", row.names = F)
?inner_join
hd_gii <- inner_join(hd, gii, by = "country")
library(dplyr)
hd_gii <- inner_join(hd, gii, by = "country")
colnames(gii)[8] <- "edu2M"
gii <- mutate(gii, labF_labM = labF / labM)
join_by <- c("HDI_rank", "country", "HDI", "life_exp", "edu_exp", "edu_mean", "GNI", "GNI_netrank", "GII_rank", "GII", "mat_mort", "adol_birth", "parl_rep", "edu2F, "edu2M", "labF", "laM", "edu2f_edu2M", "labF_labM")
?join_by
colnames(gii)[8] <- "edu2M"
gii <- mutate(gii, edu2F_edu2M = edu2F / edu2M)
gii <- mutate(gii, labF_labM = labF / labM)
hd_gii <- inner_join(hd, gii, by = "country")
options(stringsAsFactors = FALSE)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv")
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", na.strings = "..")
colnames(hd)[1] <- "HDI_rank"
colnames(hd)[2] <- "country"
colnames(hd)[3] <- "HDI"
colnames(hd)[4] <- "life_exp"
colnames(hd)[5] <- "edu_exp"
colnames(hd)[6] <- "edu_mean"
colnames(hd)[7] <- "GNI"
colnames(hd)[8] <- "GNI_netrank"
colnames(gii)[1] <- "GII_rank"
colnames(gii)[2] <- "country"
colnames(gii)[3] <- "GII"
colnames(gii)[4] <- "mat_mort"
colnames(gii)[5] <- "adol_birht"
colnames(gii)[6] <- "parl_rep"
colnames(gii)[7] <- "edu2F"
colnames(gii)[8] <- "edu2M"
colnames(gii)[9] <- "labF"
colnames(gii)[10] <- "labM"
gii <- mutate(gii, edu2F_edu2M = edu2F / edu2M)
gii <- mutate(gii, labF_labM = labF / labM)
library(dplyr)
hd_gii <- inner_join(hd, gii, by = "country")
View(hd_gii)
View(hd_gii)
View(hd)
getwd
getwd()
write.csv(hd_gii, file = "human.csv", row.names = F)
View(hd_gii)
knitr::opts_chunk$set(include= TRUE,
tidy = FALSE,
size = "small",
out.width = "70%",
fig.align = "center",
fig.width = 10,
fig.height = 10,
fig.show = "hold",
fig.path = "../figures/document/",
cache.path = "../cache/document/",
cache = TRUE,
par = TRUE,
collapse = TRUE,
echo = FALSE,
message = FALSE,
warning = FALSE
)
options(digits = 3)
options(table_counter = TRUE)
library(MASS)
library(tidyr)
library(corrplot)
library(ggplot2)
data("Boston")
str(Boston)
dim(Boston)
View(Boston)
# plot matrix
pairs(Boston)
# calculate correlation matrix and round it
cor_matrix <- cor(Boston) %>% round(digits = 2)
# print correlation matrix
cor_matrix
# visualize coorelation matrix
corrplot(cor_matrix, method = "circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)
?pairs
# plot matrix
pairs(Boston, col = "skyblue")
# plot matrix
pairs(Boston, col = "royalblue")
# standardize variables
boston_scaled <-  scale(Boston)
summary(Boston)
summary(boston_scaled)
# check class of boston_scaled object
class(boston_scaled) # matrix
# change object to data frame
boston_scaled <- as.data.frame(boston_scaled)
summary(boston_scaled$crim)
table(crime)
bins <- quantile(boston_scaled$crim)
bins <- quantile(boston_scaled$crim)
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
summary(c(Boston$crim, Boston$age, Boston$tax))
summary(Boston$age)
summary(boston_scaled$age)
summary(Boston$tax)
summary(boston_scaled$tax)
summary(Boston$black)
summary(boston_scaled$black)
# fit LDA to train set
lda.fit <- lda(data = train, crime ~.)
# print lda.fit object
lda.fit
# arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$crime)
# plot results
plot(lda.fit, dimen = 2, col = classes, pch =classes)
lda.arrows(lda.fit, myscale = 1)
# create object n for number of rows in Boston dataset
n <- nrow(boston_scaled)
# choose randomly 80% of rows
ind <- sample(n, size = n*0.8)
# create TRAIN set
train <- boston_scaled[ind,]
# create TEST set
test <-  boston_scaled[-ind,]
# fit LDA to train set
lda.fit <- lda(data = train, crime ~.)
# print lda.fit object
lda.fit
# arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$crime)
# plot results
plot(lda.fit, dimen = 2, col = classes, pch =classes)
lda.arrows(lda.fit, myscale = 1)
## remove original crim from dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)
# add new categorical variable to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
# create quantile vector of 'crim' and print it
bins <- quantile(boston_scaled$crim)
bins
# create object crime
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
# standardize variables
boston_scaled <-  scale(Boston)
# check class of boston_scaled object
class(boston_scaled) # matrix
# change object to data frame
boston_scaled <- as.data.frame(boston_scaled)
# create quantile vector of 'crim' and print it
bins <- quantile(boston_scaled$crim)
bins
# create object crime
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
## remove original crim from dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)
# add new categorical variable to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
# create object n for number of rows in Boston dataset
n <- nrow(boston_scaled)
# choose randomly 80% of rows
ind <- sample(n, size = n*0.8)
# create TRAIN set
train <- boston_scaled[ind,]
# create TEST set
test <-  boston_scaled[-ind,]
# fit LDA to train set
lda.fit <- lda(data = train, crime ~.)
# print lda.fit object
lda.fit
# arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$crime)
# plot results
plot(lda.fit, dimen = 2, col = classes, pch =classes)
lda.arrows(lda.fit, myscale = 1)
# save correct classes from test data
correct_classes <- test$crime
# remove the crime variable from test data
test <- dplyr::select(test, -crime)
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
# crosstabulate
table(correct = correct_classes, predicted = lda.pred$class)
table(correct = correct_classes, predicted = lda.pred$class) %>%
prop.table() %>%
addmargins()
table(correct = correct_classes, predicted = lda.pred$class) %>%
addmargins()
table(correct = correct_classes, predicted = lda.pred$class)
addmargins(2)
table(correct = correct_classes, predicted = lda.pred$class) %>%
addmargins(2)
table(correct = correct_classes, predicted = lda.pred$class) %>%
addmargins(1)
table(correct = correct_classes, predicted = lda.pred$class) %>%
addmargins()
table(correct = correct_classes, predicted = lda.pred$class) %>%
prop.table() %>%
addmargins(1)
table(correct = correct_classes, predicted = lda.pred$class) %>%
prop.table() %>%
addmargins()
table(correct = correct_classes, predicted = lda.pred$class) %>%
addmargins()
# reload Boston dataset
data("Boston")
# standardize
boston_scaled2 <- scale(Boston)
# calculate correlation matrix and round it
cor_matrix <- cor(Boston) %>% round(digits = 2)
# print correlation matrix
cor_matrix
# reload Boston dataset
data("Boston")
# standardize
boston_scaled2 <- scale(Boston)
# Euclidean distance matrix
dist <- dist(boston_scaled2)
summary(dist)
# k-means clustering / Euclidean
km <- kmeans(dist, centers = 10)
?kmeans
# determine number of clusters
k_max <- 5
# calculate WCSS
twcss <- sapply(1:k_max, function(k){kmeans(dist, k)$tot.withinss})
# optimalm number of clusters
qplot(x = 1:k_max, y = twcss, geom = "line") # drops at 2
# run k-means again with optimal number of clusters
km <- kmeans(dist, centers = 2)
# visualize with optimal number of clusters
pairs(boston_scaled2, col = km$cluster)
k_max <- 10
twcss <- sapply(1:k_max, function(k){kmeans(dist, k)$tot.withinss})
qplot(x = 1:k_max, y = twcss, geom = "line") # drops at 2
# Euclidean distance matrix using set.seed()
set.seed(123)
dist <- dist(boston_scaled2)
summary(dist)
# run k-means again with optimal number of clusters
km <- kmeans(dist, centers = 2)
# visualize with optimal number of clusters
pairs(boston_scaled2, col = km$cluster)
?pairs
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = classes)
model_predictors <- dplyr::select(train, -crime)
# check the dimensions
dim(model_predictors)
dim(lda.fit$scaling)
# matrix multiplication
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
library(plotly)
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = classes)
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', col = classes)
?scatter3s
?plot_ly
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', colors = classes)
model_predictors <- dplyr::select(train, -crime)
# check the dimensions
dim(model_predictors)
dim(lda.fit$scaling)
# matrix multiplication
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
library(plotly)
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', colors = classes)
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = classes)
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', colors = km)
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
# 3D plot of columns of the matrix product
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km)
load(Boston)
data("Boston"")
data("Boston")
